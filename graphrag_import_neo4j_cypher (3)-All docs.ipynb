{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fea928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bc9ba",
   "metadata": {},
   "source": [
    "# Neo4j Import of GraphRAG Result Parquet files\n",
    "\n",
    "This notebook imports the results of the GraphRAG indexing process into the Neo4j Graph database for further processing, analysis or visualization. \n",
    "\n",
    "You can also build your own GenAI applications using Neo4j and a number of RAG strategies with LangChain, LlamaIndex, Haystack, and many other frameworks.\n",
    "See: https://neo4j.com/labs/genai-ecosystem\n",
    "\n",
    "Here is what the end result looks like:\n",
    "\n",
    "![](https://dev.assets.neo4j.com/wp-content/uploads/graphrag-neo4j-visualization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3924e246",
   "metadata": {},
   "source": [
    "## How does it work?\n",
    "\n",
    "The notebook loads the parquet files from the `output` folder of your indexing process and loads them into Pandas dataframes.\n",
    "It then uses a batching approach to send a slice of the data into Neo4j to create nodes and relationships and add relevant properties. The id-arrays on most entities are turned into relationships. \n",
    "\n",
    "All operations use MERGE, so they are idempotent, and you can run the script multiple times.\n",
    "\n",
    "If you need to clean out the database, you can run the following statement\n",
    "\n",
    "```cypher\n",
    "MATCH (n)\n",
    "CALL { WITH n DETACH DELETE n } IN TRANSACTIONS OF 25000 ROWS;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adca1803",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHRAG_FOLDER = \"C:/Users/TusharJain/ragtest/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "### Depedendencies\n",
    "\n",
    "We only need Pandas and the neo4j Python driver with the rust extension for faster network transport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b57beec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet pandas neo4j-rust-ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eeee95f-e4f2-4052-94fb-a5dc8ab542ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307dd2f4",
   "metadata": {},
   "source": [
    "## Neo4j Installation\n",
    "\n",
    "You can create a free instance of Neo4j [online](https://console.neo4j.io). You get a credentials file that you can use for the connection credentials. You can also get an instance in any of the cloud marketplaces.\n",
    "\n",
    "If you want to install Neo4j locally either use [Neo4j Desktop](https://neo4j.com/download) or \n",
    "the official Docker image: `docker run -e NEO4J_AUTH=neo4j/password -p 7687:7687 -p 7474:7474 neo4j` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c15443-4acb-4f91-88ea-4e08abaa4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"neo4j+s://f17ab497.databases.neo4j.io\"  # or neo4j+s://xxxx.databases.neo4j.io\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"VCTkSYItsCMWq6S_jL6iozFcHEtSkTn7wCRIBpJQNDE\"  # your password\n",
    "NEO4J_DATABASE = \"neo4j\"\n",
    "\n",
    "# Create a Neo4j driver\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f37ab6",
   "metadata": {},
   "source": [
    "## Batched Import\n",
    "\n",
    "The batched import function takes a Cypher insert statement (needs to use the variable `value` for the row) and a dataframe to import.\n",
    "It will send by default 1k rows at a time as query parameter to the database to be inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d787bf7b-ac9b-4bfb-b140-a50a3fd205c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_import(statement, df, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Import a dataframe into Neo4j using a batched approach.\n",
    "\n",
    "    Parameters: statement is the Cypher query to execute, df is the dataframe to import, and batch_size is the number of rows to import in each batch.\n",
    "    \"\"\"\n",
    "    total = len(df)\n",
    "    start_s = time.time()\n",
    "    for start in range(0, total, batch_size):\n",
    "        batch = df.iloc[start : min(start + batch_size, total)]\n",
    "        result = driver.execute_query(\n",
    "            \"UNWIND $rows AS value \" + statement,\n",
    "            rows=batch.to_dict(\"records\"),\n",
    "            database_=NEO4J_DATABASE,\n",
    "        )\n",
    "        print(result.summary.counters)\n",
    "    print(f\"{total} rows in {time.time() - start_s} s.\")\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb45f42",
   "metadata": {},
   "source": [
    "## Indexes and Constraints\n",
    "\n",
    "Indexes in Neo4j are only used to find the starting points for graph queries, e.g. quickly finding two nodes to connect.\n",
    "Constraints exist to avoid duplicates, we create them mostly on id's of Entity types.\n",
    "\n",
    "We use some Types as markers with two underscores before and after to distinguish them from the actual entity types.\n",
    "\n",
    "The default relationship type here is `RELATED` but we could also infer a real relationship-type from the description or the types of the start and end-nodes.\n",
    "\n",
    "* `__Entity__`\n",
    "* `__Document__`\n",
    "* `__Chunk__`\n",
    "* `__Community__`\n",
    "* `__Covariate__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7f212e-9148-424c-adc6-d81db9f8e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create constraints, idempotent operation\n",
    "\n",
    "# statements = \"\"\"\n",
    "# create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique;\n",
    "# create constraint document_id if not exists for (d:__Document__) require d.id is unique;\n",
    "# create constraint entity_id if not exists for (c:__Community__) require c.community is unique;\n",
    "# create constraint entity_id if not exists for (e:__Entity__) require e.id is unique;\n",
    "# create constraint entity_title if not exists for (e:__Entity__) require e.name is unique;\n",
    "# create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique;\n",
    "# create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique;\n",
    "# \"\"\".split(\";\")\n",
    "\n",
    "# for statement in statements:\n",
    "#     if len((statement or \"\").strip()) > 0:\n",
    "#         print(statement)\n",
    "#         driver.execute_query(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea073b",
   "metadata": {},
   "source": [
    "## Import Process\n",
    "\n",
    "### Importing the Documents\n",
    "\n",
    "We're loading the parquet file for the documents and create nodes with their ids and add the title property.\n",
    "We don't need to store text_unit_ids as we can create the relationships and the text content is also contained in the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba023e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>675b5991cecfe09978375ab0bd2c6cc1</td>\n",
       "      <td>Class export.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59e7890c3a3585b04faee5f1547f0b2e</td>\n",
       "      <td>function compilation.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                     title\n",
       "0  675b5991cecfe09978375ab0bd2c6cc1          Class export.txt\n",
       "1  59e7890c3a3585b04faee5f1547f0b2e  function compilation.txt"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_documents.parquet\", columns=[\"id\", \"title\"]\n",
    ")\n",
    "doc_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96391c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'properties_set': 3}\n",
      "3 rows in 1.311204433441162 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import documents\n",
    "statement = \"\"\"\n",
    "MERGE (d:__Document__ {id:value.id})\n",
    "SET d += value {.title}\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, doc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97bbadb",
   "metadata": {},
   "source": [
    "### Loading Text Units\n",
    "\n",
    "We load the text units, create a node per id and set the text and number of tokens.\n",
    "Then we connect them to the documents that we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d825626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9fe05946567c481b265abefd72089ed1</td>\n",
       "      <td>**********************************************...</td>\n",
       "      <td>1200</td>\n",
       "      <td>[0d1514a1958b087cee042478fb199791]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4831fc8424e707db3a38d845acdf498c</td>\n",
       "      <td>_hotspot_click      FOR EVENT hotspot_click\\n ...</td>\n",
       "      <td>1200</td>\n",
       "      <td>[0d1514a1958b087cee042478fb199791]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  9fe05946567c481b265abefd72089ed1   \n",
       "1  4831fc8424e707db3a38d845acdf498c   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  **********************************************...      1200   \n",
       "1  _hotspot_click      FOR EVENT hotspot_click\\n ...      1200   \n",
       "\n",
       "                         document_ids  \n",
       "0  [0d1514a1958b087cee042478fb199791]  \n",
       "1  [0d1514a1958b087cee042478fb199791]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_text_units.parquet\",\n",
    "    columns=[\"id\", \"text\", \"n_tokens\", \"document_ids\"],\n",
    ")\n",
    "text_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd3d380-8710-46f5-b90a-04ed8482192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'properties_set': 1212}\n",
      "606 rows in 1.3756356239318848 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"\n",
    "MERGE (c:__Chunk__ {id:value.id})\n",
    "SET c += value {.text, .n_tokens}\n",
    "WITH c, value\n",
    "UNWIND value.document_ids AS document\n",
    "MATCH (d:__Document__ {id:document})\n",
    "MERGE (c)-[:PART_OF]->(d)\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01b2094",
   "metadata": {},
   "source": [
    "### Loading Nodes\n",
    "\n",
    "For the nodes we store id, name, description, embedding (if available), human readable id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2392f9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>id</th>\n",
       "      <th>description_embedding</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/CGDC/LCLRQMU04</td>\n",
       "      <td>INCLUDE</td>\n",
       "      <td>Include statement for CLRQ_PROCESS functionality</td>\n",
       "      <td>0</td>\n",
       "      <td>d69b4aa7f613480fbea468bd689bffeb</td>\n",
       "      <td>[0.01129966415464878, 0.0364234521985054, 0.04...</td>\n",
       "      <td>[9fe05946567c481b265abefd72089ed1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/CGDC/LCLRQMU05</td>\n",
       "      <td>INCLUDE</td>\n",
       "      <td>Include statement for CLRQ_RTBC_PROCESS functi...</td>\n",
       "      <td>1</td>\n",
       "      <td>9f54a217d9974b9cad80538f9db53731</td>\n",
       "      <td>[0.013413391076028347, 0.023699110373854637, 0...</td>\n",
       "      <td>[9fe05946567c481b265abefd72089ed1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name     type  \\\n",
       "0  /CGDC/LCLRQMU04  INCLUDE   \n",
       "1  /CGDC/LCLRQMU05  INCLUDE   \n",
       "\n",
       "                                         description  human_readable_id  \\\n",
       "0   Include statement for CLRQ_PROCESS functionality                  0   \n",
       "1  Include statement for CLRQ_RTBC_PROCESS functi...                  1   \n",
       "\n",
       "                                 id  \\\n",
       "0  d69b4aa7f613480fbea468bd689bffeb   \n",
       "1  9f54a217d9974b9cad80538f9db53731   \n",
       "\n",
       "                               description_embedding  \\\n",
       "0  [0.01129966415464878, 0.0364234521985054, 0.04...   \n",
       "1  [0.013413391076028347, 0.023699110373854637, 0...   \n",
       "\n",
       "                        text_unit_ids  \n",
       "0  [9fe05946567c481b265abefd72089ed1]  \n",
       "1  [9fe05946567c481b265abefd72089ed1]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_entities.parquet\",\n",
    "    columns=[\n",
    "        \"name\",\n",
    "        \"type\",\n",
    "        \"description\",\n",
    "        \"human_readable_id\",\n",
    "        \"id\",\n",
    "        \"description_embedding\",\n",
    "        \"text_unit_ids\",\n",
    "    ],\n",
    ")\n",
    "entity_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d038114-0714-48ee-a48a-c421cd539661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'properties_set': 3000}\n",
      "{'_contains_updates': True, 'properties_set': 3000}\n"
     ]
    },
    {
     "ename": "ConstraintError",
     "evalue": "{code: Neo.ClientError.Schema.ConstraintValidationFailed} {message: Node(2802) already exists with label `__Entity__` and property `name` = '/CGDC/CLRQ_SAVE'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConstraintError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m entity_statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mMERGE (e:__Entity__ \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mid:value.id})\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mSET e += value \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m.human_readable_id, .description, name:replace(value.name,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)}\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mMERGE (c)-[:HAS_ENTITY]->(e)\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mbatched_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36mbatched_import\u001b[1;34m(statement, df, batch_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, total, batch_size):\n\u001b[0;32m     10\u001b[0m     batch \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[start : \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m+\u001b[39m batch_size, total)]\n\u001b[1;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUNWIND $rows AS value \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNEO4J_DATABASE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mcounters)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_s\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\driver.py:971\u001b[0m, in \u001b[0;36mDriver.execute_query\u001b[1;34m(self, query_, parameters_, routing_, database_, impersonated_user_, bookmark_manager_, auth_, result_transformer_, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    968\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid routing control value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrouting_\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    969\u001b[0m     )\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_pipelined_begin:\n\u001b[1;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_transaction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTelemetryAPI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDRIVER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_transformer_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:574\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[1;34m(self, access_mode, api, transaction_function, args, kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 574\u001b[0m     result \u001b[38;5;241m=\u001b[39m transaction_function(tx, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mCancelledError:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# if cancellation callback has not been called yet:\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transaction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\driver.py:1307\u001b[0m, in \u001b[0;36m_work\u001b[1;34m(tx, query, parameters, transformer)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_work\u001b[39m(\n\u001b[0;32m   1302\u001b[0m     tx: ManagedTransaction,\n\u001b[0;32m   1303\u001b[0m     query: te\u001b[38;5;241m.\u001b[39mLiteralString,\n\u001b[0;32m   1304\u001b[0m     parameters: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny],\n\u001b[0;32m   1305\u001b[0m     transformer: t\u001b[38;5;241m.\u001b[39mCallable[[Result], t\u001b[38;5;241m.\u001b[39mUnion[_T]],\n\u001b[0;32m   1306\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m-> 1307\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transformer(res)\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\work\\transaction.py:195\u001b[0m, in \u001b[0;36mTransactionBase.run\u001b[1;34m(self, query, parameters, **kwparameters)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m    194\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(parameters \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwparameters)\n\u001b[1;32m--> 195\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tx_ready_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\work\\result.py:175\u001b[0m, in \u001b[0;36mResult._tx_ready_run\u001b[1;34m(self, query, parameters)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tx_ready_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, parameters):\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# BEGIN+RUN does not carry any extra on the RUN message.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# BEGIN {extra}\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# RUN \"query\" {parameters} {extra}\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\work\\result.py:231\u001b[0m, in \u001b[0;36mResult._run\u001b[1;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pull()\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39msend_all()\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\work\\result.py:425\u001b[0m, in \u001b[0;36mResult._attach\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exhausted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 425\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\io\\_common.py:181\u001b[0m, in \u001b[0;36mConnectionErrorHandler.__getattr__.<locals>.outer.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m         func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (Neo4jError, ServiceUnavailable, SessionExpired) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39miscoroutinefunction(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__on_error)\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:977\u001b[0m, in \u001b[0;36mBolt.fetch_message\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# Receive exactly one message\u001b[39;00m\n\u001b[0;32m    974\u001b[0m tag, fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minbox\u001b[38;5;241m.\u001b[39mpop(\n\u001b[0;32m    975\u001b[0m     hydration_hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhydration_hooks\n\u001b[0;32m    976\u001b[0m )\n\u001b[1;32m--> 977\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midle_since \u001b[38;5;241m=\u001b[39m monotonic()\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py:466\u001b[0m, in \u001b[0;36mBolt5x0._process_message\u001b[1;34m(self, tag, fields)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_server_state_manager\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbolt_states\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_failure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummary_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ServiceUnavailable, DatabaseUnavailable):\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool:\n",
      "File \u001b[1;32mc:\\Users\\TusharJain\\anaconda3\\envs\\KGRAPH\\lib\\site-packages\\neo4j\\_sync\\io\\_common.py:251\u001b[0m, in \u001b[0;36mResponse.on_failure\u001b[1;34m(self, metadata)\u001b[0m\n\u001b[0;32m    249\u001b[0m handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m Util\u001b[38;5;241m.\u001b[39mcallback(handler)\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m Neo4jError\u001b[38;5;241m.\u001b[39mhydrate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata)\n",
      "\u001b[1;31mConstraintError\u001b[0m: {code: Neo.ClientError.Schema.ConstraintValidationFailed} {message: Node(2802) already exists with label `__Entity__` and property `name` = '/CGDC/CLRQ_SAVE'}"
     ]
    }
   ],
   "source": [
    "entity_statement = \"\"\"\n",
    "MERGE (e:__Entity__ {id:value.id})\n",
    "SET e += value {.human_readable_id, .description, name:replace(value.name,'\"','')}\n",
    "WITH e, value\n",
    "CALL db.create.setNodeVectorProperty(e, \"description_embedding\", value.description_embedding)\n",
    "CALL apoc.create.addLabels(e, case when coalesce(value.type,\"\") = \"\" then [] else [apoc.text.upperCamelCase(replace(value.type,'\"',''))] end) yield node\n",
    "UNWIND value.text_unit_ids AS text_unit\n",
    "MATCH (c:__Chunk__ {id:text_unit})\n",
    "MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "\"\"\"\n",
    "\n",
    "batched_import(entity_statement, entity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "619f3170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               name      type  \\\n",
      "0             /CGDC/CL_CLRQ_PROCESS     CLASS   \n",
      "1                    GTT_CR_DOCTYPE      TYPE   \n",
      "2                  GTY_CF_POP_ENDAT      TYPE   \n",
      "3                  GTT_CF_POP_ENDAT      TYPE   \n",
      "4                      GTT_CLRQ_ERR      TYPE   \n",
      "..                              ...       ...   \n",
      "165  /CGDC/CLRQ_TRGR_REAL_TIME_PRCS  FUNCTION   \n",
      "166                        LT_TABLE  VARIABLE   \n",
      "167                            COEP     TABLE   \n",
      "168                            COBK     TABLE   \n",
      "169                           COEPR     TABLE   \n",
      "\n",
      "                                           description  human_readable_id  \\\n",
      "0    The \"/CGDC/CL_CLRQ_PROCESS\" is an ABAP class s...                  0   \n",
      "1    Standard table type for document types in the ...                  1   \n",
      "2    Structure type defining fields for performance...                  2   \n",
      "3    Standard table type of gty_cf_pop_endat for st...                  3   \n",
      "4    Standard table type for error messages in the ...                  4   \n",
      "..                                                 ...                ...   \n",
      "165  A function module called in an update task, wh...                507   \n",
      "166  A local table variable assigned to the dynamic...                508   \n",
      "167  A standard SAP table used for storing Controll...                509   \n",
      "168  A standard SAP table used for storing Controll...                510   \n",
      "169  A standard SAP table used for storing Controll...                511   \n",
      "\n",
      "                                   id  \\\n",
      "0    4c862c39c3fa4e81a8450d3c97c820cc   \n",
      "1    81ca41ebb3c0439a804a7214b4d9f1ea   \n",
      "2    30530d52346d4a1ca71f9a32c0223acc   \n",
      "3    c04c378de3d24f0685199dc7854749fc   \n",
      "4    72c91d1a62b64b87af184b136557a158   \n",
      "..                                ...   \n",
      "165  371b75558c84417596b8cc13c4b45822   \n",
      "166  34123570535d489c9a817c34c34420a4   \n",
      "167  c3ea4dec107a4fde871ea0943d3cce75   \n",
      "168  96f82fede2964538831a0134c9cae080   \n",
      "169  a98571f061074395bd700e83ba58e1c1   \n",
      "\n",
      "                                 description_embedding  \\\n",
      "0    [-0.021158946678042412, 0.06394816935062408, 0...   \n",
      "1    [-0.040688782930374146, 0.05645693093538284, 0...   \n",
      "2    [-0.0130550442263484, 0.05362745746970177, 0.0...   \n",
      "3    [0.00516247283667326, 0.023798540234565735, 0....   \n",
      "4    [-0.017108211293816566, 0.04634770005941391, 0...   \n",
      "..                                                 ...   \n",
      "165  [-0.02854187972843647, 0.05923733860254288, 0....   \n",
      "166  [-0.007416928187012672, 0.012594184838235378, ...   \n",
      "167  [-0.017433814704418182, 0.031742047518491745, ...   \n",
      "168  [-0.005089866928756237, 0.04137493669986725, 0...   \n",
      "169  [0.0017636687261983752, 0.037171620875597, 0.0...   \n",
      "\n",
      "                                         text_unit_ids  \n",
      "0    [02518262df9188eb68cefe5a80524002, 0a9879312a2...  \n",
      "1                   [77afae11468def2f00d30a57c55c02c8]  \n",
      "2                   [77afae11468def2f00d30a57c55c02c8]  \n",
      "3                   [77afae11468def2f00d30a57c55c02c8]  \n",
      "4                   [77afae11468def2f00d30a57c55c02c8]  \n",
      "..                                                 ...  \n",
      "165                 [14bfc894ceb39155b78b54ac760ed6c5]  \n",
      "166                 [14bfc894ceb39155b78b54ac760ed6c5]  \n",
      "167                 [14bfc894ceb39155b78b54ac760ed6c5]  \n",
      "168                 [14bfc894ceb39155b78b54ac760ed6c5]  \n",
      "169                 [14bfc894ceb39155b78b54ac760ed6c5]  \n",
      "\n",
      "[512 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates based on 'name' and 'type' columns, keeping the first occurrence\n",
    "entity_df = entity_df.drop_duplicates(subset=['name', 'type'], keep='first')\n",
    "print(entity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8b5b6f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name   type                                        description  \\\n",
      "5  /CGDC/_CLRQHD  TABLE  The entity \"/CGDC/_CLRQHD\" refers to a custom ...   \n",
      "\n",
      "   human_readable_id                                id  \\\n",
      "5                176  e56afc402f2b4587862c794a193e84b9   \n",
      "\n",
      "                               description_embedding  \\\n",
      "5  [-0.016181832179427147, 0.04186629503965378, 0...   \n",
      "\n",
      "                                       text_unit_ids  \n",
      "5  [1590fdd44a1ddf4fedc40fe600d8ebeb, 360d31cc8ed...  \n"
     ]
    }
   ],
   "source": [
    "# Filter the entity_df to find rows where the name column contains '/CGDC/_CLRQHD'\n",
    "filtered_df = entity_df[entity_df['name'].str.contains('/CGDC/_CLRQHD')]\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "902c1a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [name, type, description, human_readable_id, id, description_embedding, text_unit_ids]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in entity_df based on the 'id' column\n",
    "duplicates = entity_df[entity_df.duplicated(subset='name', keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d4f87",
   "metadata": {},
   "source": [
    "### Import Relationships\n",
    "\n",
    "For the relationships we find the source and target node by name, using the base `__Entity__` type.\n",
    "After creating the `RELATED` relationships, we set the description as attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b347a047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>weight</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/CGDC/CL_CLRQ_PROCESS</td>\n",
       "      <td>GTT_CR_DOCTYPE</td>\n",
       "      <td>2e972777cbd843d481fb120205e5ec42</td>\n",
       "      <td>50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>The gtt_cr_doctype type is defined within the ...</td>\n",
       "      <td>[77afae11468def2f00d30a57c55c02c8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/CGDC/CL_CLRQ_PROCESS</td>\n",
       "      <td>GC_ITM_BILL_STATUS</td>\n",
       "      <td>2cc08790c74c4eaf945b974b06ad579e</td>\n",
       "      <td>53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>The gc_itm_bill_status constants are defined w...</td>\n",
       "      <td>[77afae11468def2f00d30a57c55c02c8]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  source              target  \\\n",
       "0  /CGDC/CL_CLRQ_PROCESS      GTT_CR_DOCTYPE   \n",
       "1  /CGDC/CL_CLRQ_PROCESS  GC_ITM_BILL_STATUS   \n",
       "\n",
       "                                 id  rank  weight human_readable_id  \\\n",
       "0  2e972777cbd843d481fb120205e5ec42    50    10.0                 0   \n",
       "1  2cc08790c74c4eaf945b974b06ad579e    53    10.0                 1   \n",
       "\n",
       "                                         description  \\\n",
       "0  The gtt_cr_doctype type is defined within the ...   \n",
       "1  The gc_itm_bill_status constants are defined w...   \n",
       "\n",
       "                        text_unit_ids  \n",
       "0  [77afae11468def2f00d30a57c55c02c8]  \n",
       "1  [77afae11468def2f00d30a57c55c02c8]  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_relationships.parquet\",\n",
    "    columns=[\n",
    "        \"source\",\n",
    "        \"target\",\n",
    "        \"id\",\n",
    "        \"rank\",\n",
    "        \"weight\",\n",
    "        \"human_readable_id\",\n",
    "        \"description\",\n",
    "        \"text_unit_ids\",\n",
    "    ],\n",
    ")\n",
    "rel_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "27900c01-89e1-4dec-9d5c-c07317c68baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'relationships_created': 548, 'properties_set': 3288}\n",
      "548 rows in 0.7544255256652832 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_statement = \"\"\"\n",
    "    MATCH (source:__Entity__ {name:replace(value.source,'\"','')})\n",
    "    MATCH (target:__Entity__ {name:replace(value.target,'\"','')})\n",
    "    // not necessary to merge on id as there is only one relationship per pair\n",
    "    MERGE (source)-[rel:RELATED {id: value.id}]->(target)\n",
    "    SET rel += value {.rank, .weight, .human_readable_id, .description, .text_unit_ids}\n",
    "    RETURN count(*) as createdRels\n",
    "\"\"\"\n",
    "\n",
    "batched_import(rel_statement, rel_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6365dd7",
   "metadata": {},
   "source": [
    "### Importing Communities\n",
    "\n",
    "For communities we import their id, title, level.\n",
    "We connect the `__Community__` nodes to the start and end nodes of the relationships they refer to.\n",
    "\n",
    "Connecting them to the chunks they orignate from is optional, as the entites are already connected to the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2fab66c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 3</td>\n",
       "      <td>[02518262df9188eb68cefe5a80524002,0a9879312a25...</td>\n",
       "      <td>[2e972777cbd843d481fb120205e5ec42, 2cc08790c74...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>Community 16</td>\n",
       "      <td>[05155c2d98a9cff7f7f3d2dacc83583a,66ce6976b36a...</td>\n",
       "      <td>[cd8c4e7b89fe45ce944a46c404d03ad6, 756b2e05f60...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  level         title                                      text_unit_ids  \\\n",
       "0   3      0   Community 3  [02518262df9188eb68cefe5a80524002,0a9879312a25...   \n",
       "1  16      0  Community 16  [05155c2d98a9cff7f7f3d2dacc83583a,66ce6976b36a...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [2e972777cbd843d481fb120205e5ec42, 2cc08790c74...  \n",
       "1  [cd8c4e7b89fe45ce944a46c404d03ad6, 756b2e05f60...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_communities.parquet\",\n",
    "    columns=[\"id\", \"level\", \"title\", \"text_unit_ids\", \"relationship_ids\"],\n",
    ")\n",
    "\n",
    "community_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1351f7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 91, 'relationships_created': 1301, 'nodes_created': 91, 'properties_set': 273}\n",
      "91 rows in 0.6258261203765869 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.id})\n",
    "SET c += value {.level, .title}\n",
    "/*\n",
    "UNWIND value.text_unit_ids as text_unit_id\n",
    "MATCH (t:__Chunk__ {id:text_unit_id})\n",
    "MERGE (c)-[:HAS_CHUNK]->(t)\n",
    "WITH distinct c, value\n",
    "*/\n",
    "WITH *\n",
    "UNWIND value.relationship_ids as rel_id\n",
    "MATCH (start:__Entity__)-[:RELATED {id:rel_id}]->(end:__Entity__)\n",
    "MERGE (start)-[:IN_COMMUNITY]->(c)\n",
    "MERGE (end)-[:IN_COMMUNITY]->(c)\n",
    "RETURn count(distinct c) as createdCommunities\n",
    "\"\"\"\n",
    "\n",
    "batched_import(statement, community_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9adf50",
   "metadata": {},
   "source": [
    "### Importing Community Reports\n",
    "\n",
    "Fo the community reports we create nodes for each communitiy set the id, community, level, title, summary, rank, and rank_explanation and connect them to the entities they are about.\n",
    "For the findings we create the findings in context of the communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1be9e7a9-69ee-406b-bce5-95a9c41ecffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>community</th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>rank</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a926b1ad-cdcd-4ad3-8a03-5c919763d773</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>SAP ABAP /CGDC/CL_CLRQ_PROCESS Class Ecosystem</td>\n",
       "      <td>This report delves into the /CGDC/CL_CLRQ_PROC...</td>\n",
       "      <td>[{'explanation': 'The /CGDC/CL_CLRQ_PROCESS cl...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>The rating reflects the high relevance of this...</td>\n",
       "      <td># SAP ABAP /CGDC/CL_CLRQ_PROCESS Class Ecosyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88908cb7-fdff-4561-8ad7-9f4bfc586043</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>RTB_DOC_USAGE_CHECK and its Role in SAP ABAP D...</td>\n",
       "      <td>The RTB_DOC_USAGE_CHECK method is a specialize...</td>\n",
       "      <td>[{'explanation': 'RTB_DOC_USAGE_CHECK is a piv...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>This report is highly relevant to software dev...</td>\n",
       "      <td># RTB_DOC_USAGE_CHECK and its Role in SAP ABAP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id community  level  \\\n",
       "0  a926b1ad-cdcd-4ad3-8a03-5c919763d773        79      2   \n",
       "1  88908cb7-fdff-4561-8ad7-9f4bfc586043        80      2   \n",
       "\n",
       "                                               title  \\\n",
       "0     SAP ABAP /CGDC/CL_CLRQ_PROCESS Class Ecosystem   \n",
       "1  RTB_DOC_USAGE_CHECK and its Role in SAP ABAP D...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This report delves into the /CGDC/CL_CLRQ_PROC...   \n",
       "1  The RTB_DOC_USAGE_CHECK method is a specialize...   \n",
       "\n",
       "                                            findings  rank  \\\n",
       "0  [{'explanation': 'The /CGDC/CL_CLRQ_PROCESS cl...   9.5   \n",
       "1  [{'explanation': 'RTB_DOC_USAGE_CHECK is a piv...   9.0   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The rating reflects the high relevance of this...   \n",
       "1  This report is highly relevant to software dev...   \n",
       "\n",
       "                                        full_content  \n",
       "0  # SAP ABAP /CGDC/CL_CLRQ_PROCESS Class Ecosyst...  \n",
       "1  # RTB_DOC_USAGE_CHECK and its Role in SAP ABAP...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community_report_df = pd.read_parquet(\n",
    "    f\"{GRAPHRAG_FOLDER}/create_final_community_reports.parquet\",\n",
    "    columns=[\n",
    "        \"id\",\n",
    "        \"community\",\n",
    "        \"level\",\n",
    "        \"title\",\n",
    "        \"summary\",\n",
    "        \"findings\",\n",
    "        \"rank\",\n",
    "        \"rank_explanation\",\n",
    "        \"full_content\",\n",
    "    ],\n",
    ")\n",
    "community_report_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c6ed591-f98c-4403-9fde-8d4cb4c01cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 441, 'relationships_created': 441, 'nodes_created': 441, 'properties_set': 1869}\n",
      "91 rows in 0.5125257968902588 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import communities\n",
    "community_statement = \"\"\"\n",
    "MERGE (c:__Community__ {community:value.community})\n",
    "SET c += value {.level, .title, .rank, .rank_explanation, .full_content, .summary}\n",
    "WITH c, value\n",
    "UNWIND range(0, size(value.findings)-1) AS finding_idx\n",
    "WITH c, value, finding_idx, value.findings[finding_idx] as finding\n",
    "MERGE (c)-[:HAS_FINDING]->(f:Finding {id:finding_idx})\n",
    "SET f += finding\n",
    "\"\"\"\n",
    "batched_import(community_statement, community_report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1a24a",
   "metadata": {},
   "source": [
    "### Importing Covariates\n",
    "\n",
    "Covariates are for instance claims on entities, we connect them to the chunks where they originate from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "523bed92-d12c-4fc4-aa44-6c62321b36bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>covariate_type</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>subject_type</th>\n",
       "      <th>object_id</th>\n",
       "      <th>object_type</th>\n",
       "      <th>status</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>source_text</th>\n",
       "      <th>text_unit_id</th>\n",
       "      <th>document_ids</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9bd73361-5e94-4867-9c7c-3e4319486f85</td>\n",
       "      <td>1</td>\n",
       "      <td>claim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No claims or facts relevant to information dis...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>77afae11468def2f00d30a57c55c02c8</td>\n",
       "      <td>[675b5991cecfe09978375ab0bd2c6cc1]</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12a69a30-ae08-4d24-9148-9f9de96cfca8</td>\n",
       "      <td>2</td>\n",
       "      <td>claim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>29a7062d6a5b159a1c53444e91625410</td>\n",
       "      <td>[675b5991cecfe09978375ab0bd2c6cc1]</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id human_readable_id covariate_type  \\\n",
       "0  9bd73361-5e94-4867-9c7c-3e4319486f85                 1          claim   \n",
       "1  12a69a30-ae08-4d24-9148-9f9de96cfca8                 2          claim   \n",
       "\n",
       "   type description                                         subject_id  \\\n",
       "0  None        None  No claims or facts relevant to information dis...   \n",
       "1  None        None                                                      \n",
       "\n",
       "  subject_type object_id object_type status start_date end_date source_text  \\\n",
       "0         None      None        None   None       None     None        None   \n",
       "1         None      None        None   None       None     None        None   \n",
       "\n",
       "                       text_unit_id                        document_ids  \\\n",
       "0  77afae11468def2f00d30a57c55c02c8  [675b5991cecfe09978375ab0bd2c6cc1]   \n",
       "1  29a7062d6a5b159a1c53444e91625410  [675b5991cecfe09978375ab0bd2c6cc1]   \n",
       "\n",
       "   n_tokens  \n",
       "0      1200  \n",
       "1      1200  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_df = pd.read_parquet(f\"{GRAPHRAG_FOLDER}/create_final_covariates.parquet\")\n",
    "#                         columns=[\"id\",\"text_unit_id\"])\n",
    "cov_df.head(2)\n",
    "# Subject id do not match entity ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e064234-5fce-448e-8bb4-ab2f35699049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_contains_updates': True, 'labels_added': 52, 'relationships_created': 52, 'nodes_created': 52, 'properties_set': 267}\n",
      "52 rows in 0.20680952072143555 s.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import covariates\n",
    "cov_statement = \"\"\"\n",
    "MERGE (c:__Covariate__ {id:value.id})\n",
    "SET c += apoc.map.clean(value, [\"text_unit_id\", \"document_ids\", \"n_tokens\"], [NULL, \"\"])\n",
    "WITH c, value\n",
    "MATCH (ch:__Chunk__ {id: value.text_unit_id})\n",
    "MERGE (ch)-[:HAS_COVARIATE]->(c)\n",
    "\"\"\"\n",
    "batched_import(cov_statement, cov_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00340bae",
   "metadata": {},
   "source": [
    "### Visualize your data\n",
    "\n",
    "You can now [Open] Neo4j on Aura, you need to log in with either SSO or your credentials.\n",
    "\n",
    "Or open https://workspace-preview.neo4j.io and connect to your local instance, remember the URI is `neo4j://localhost` and `neo4j` as username and `password` as password.\n",
    "\n",
    "In \"Explore\" you can explore by using visual graph patterns and then explore and expand further.\n",
    "\n",
    "In \"Query\", you can open the left sidebar and explore by clicking on the nodes and relationships.\n",
    "You can also use the co-pilot to generate Cypher queries for your, here are some examples.\n",
    "\n",
    "#### Show a few `__Entity__` nodes and their relationships (Entity Graph)\n",
    "\n",
    "```cypher\n",
    "MATCH path = (:__Entity__)-[:RELATED]->(:__Entity__)\n",
    "RETURN path LIMIT 200\n",
    "```\n",
    "\n",
    "#### Show the Chunks and the Document (Lexical Graph)\n",
    "\n",
    "```cypher\n",
    "MATCH (d:__Document__) WITH d LIMIT 1\n",
    "MATCH path = (d)<-[:PART_OF]-(c:__Chunk__)\n",
    "RETURN path LIMIT 100\n",
    "```\n",
    "\n",
    "####  Show a Community and it's Entities\n",
    "\n",
    "```cypher\n",
    "MATCH (c:__Community__) WITH c LIMIT 1\n",
    "MATCH path = (c)<-[:IN_COMMUNITY]-()-[:RELATED]-(:__Entity__)\n",
    "RETURN path LIMIT 100\n",
    "```\n",
    "\n",
    "#### Show everything\n",
    "\n",
    "```cypher\n",
    "MATCH (d:__Document__) WITH d LIMIT 1\n",
    "MATCH path = (d)<-[:PART_OF]-(:__Chunk__)-[:HAS_ENTIY]->()-[:RELATED]-()-[:IN_COMMUNITY]->()\n",
    "RETURN path LIMIT 250\n",
    "```\n",
    "\n",
    "We showed the visualization of this last query at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0aa8529",
   "metadata": {},
   "source": [
    "If you have questions, feel free to reach out in the GraphRAG discord server: \n",
    "https://discord.gg/graphrag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KGRAPH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
